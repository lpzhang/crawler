{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_13.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_14.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_15.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_16.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_17.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_18.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_19.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_20.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "/home/lpzhang/Desktop/crawler/GoogleImages/chime/googleimage_chime_21.txt\n",
      "start from 0\n",
      "start from 100\n",
      "start from 200\n",
      "start from 300\n",
      "start from 400\n",
      "start from 500\n",
      "start from 600\n",
      "start from 700\n",
      "start from 800\n",
      "start from 900\n",
      "save image_id_url_dict\n",
      "########### done ##############\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import urllib\n",
    "import urllib2\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import sys\n",
    "import os\n",
    "import errno\n",
    "import random\n",
    "import string\n",
    "from argparse import ArgumentParser\n",
    "import time\n",
    "from six.moves.urllib.parse import urlencode\n",
    "import json \n",
    "\n",
    "def entryurl_googleimage(url, offset):\n",
    "    splitkey1 = ''\n",
    "    splitkey2 = ''\n",
    "    if 'ijn=1'in url and 'start=100' in url:\n",
    "        splitkey1 = 'ijn=1'\n",
    "        splitkey2 = 'start=100'\n",
    "    elif 'ijn=2' in url and 'start=200' in url:\n",
    "        splitkey1 = 'ijn=2'\n",
    "        splitkey2 = 'start=200'\n",
    "    elif 'ijn=3' in url and 'start=300' in url:\n",
    "        splitkey1 = 'ijn=3'\n",
    "        splitkey2 = 'start=300'\n",
    "    else:\n",
    "        print 'ijn error'\n",
    "\n",
    "    url = url.split(splitkey1)\n",
    "    url = url = '{}ijn={}{}'.format(url[0],offset//100,url[1])\n",
    "    \n",
    "    url = url.split(splitkey2)\n",
    "    url = url = '{}start={}{}'.format(url[0],offset,url[1])\n",
    "    \n",
    "    return url\n",
    "    \n",
    "def response_contents(url):\n",
    "    headers = {'user-agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.94 Safari/537.36'}\n",
    "    request = urllib2.Request(url, headers = headers)\n",
    "    try:\n",
    "        response = urllib2.urlopen(request)\n",
    "        content = response.read()\n",
    "    except urllib2.HTTPError as err:\n",
    "        content = ''\n",
    "        if err.code == 404:\n",
    "            print 'HTTP Error 404: Not Found'\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    return content\n",
    "\n",
    "def extract_infos_googleimage(content):\n",
    "    img_id_url_dict = dict()\n",
    "    \n",
    "    image_divs = BeautifulSoup(content, 'lxml').find_all('div', class_='rg_meta')\n",
    "    soup = BeautifulSoup(content, 'lxml').select('.rg_di.rg_bx.rg_el.ivg-i .rg_meta')\n",
    "    for div in image_divs:\n",
    "        try:\n",
    "            meta = json.loads(div.text)\n",
    "        except ValueError:\n",
    "            print(\"Oops!  That was No JSON object could be decoded.\")\n",
    "            continue\n",
    "        if 'ou' in meta and 'id' in meta:\n",
    "            if meta['id'] not in img_id_url_dict:\n",
    "                img_id_url_dict[meta['id']] = meta['ou']\n",
    "            \n",
    "    return img_id_url_dict\n",
    "\n",
    "# def extract_infos_googleimage(content):\n",
    "#     img_id_url_dict = dict()\n",
    "#     soup = BeautifulSoup(content, 'lxml')\n",
    "#     meta = str(json.loads(soup.text))\n",
    "#     soup = BeautifulSoup(meta, 'lxml').select('.rg_meta')\n",
    "    \n",
    "#     ou_pattern = re.compile(r'\"ou\":\"(.*?)\",\"ow\"')\n",
    "#     id_pattern = re.compile(r'\"id\":\"(.*?):\",\"isu\"')\n",
    "#     ity_pattern = re.compile(r'\"ity\":\"(.*?)\",\"oh\"')\n",
    "#     url_pattern = re.compile(r'(.*?).jpg')\n",
    "    \n",
    "#     for meta in soup:\n",
    "#         meta = str(meta)\n",
    "#         ou_find = re.findall(ou_pattern, meta)\n",
    "#         id_find = re.findall(id_pattern, meta)\n",
    "#         if len(ou_find)==0 or len(id_find)==0:\n",
    "#             continue\n",
    "#         ou_find = ou_find[0]\n",
    "#         imgid = id_find[0]\n",
    "#         ity_find = re.findall(ity_pattern, meta)\n",
    "#         if len(ity_find):\n",
    "#             url_find = re.findall(url_pattern, ou_find)\n",
    "#             if len(url_find)==0:\n",
    "#                 continue\n",
    "#             imgurl = url_find[0] + '.jpg'\n",
    "#         if imgid not in img_id_url_dict:\n",
    "#             img_id_url_dict[imgid] = imgurl\n",
    "            \n",
    "#     return img_id_url_dict\n",
    "\n",
    "def save_infos(img_id_url_dict, idprefix, fname):\n",
    "    fid = open(fname, 'w')\n",
    "\n",
    "    for imgid in img_id_url_dict:\n",
    "        imgurl = img_id_url_dict[imgid]\n",
    "        try:\n",
    "            fid.write(idprefix+ '_' + str(imgid) + '   ' + imgurl + '\\n')\n",
    "        except Exception,e:\n",
    "            print Exception,\":\",e\n",
    "\n",
    "    fid.close()\n",
    "\n",
    "def _mkdir_p(path):\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as exc: # Python >2.5 (except OSError, exc: for Python <2.5)\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "def main(keyword, initurl):\n",
    "    offset = 0\n",
    "    max_num = 1000\n",
    "    idprefix='googleimage'\n",
    "    extension = 'txt'\n",
    "    outdir = '/home/lpzhang/Desktop/crawler/GoogleImages'\n",
    "    \n",
    "    img_dir = os.path.join(outdir, '_'.join(keyword.split()))\n",
    "    _mkdir_p(img_dir)\n",
    "    assert os.path.exists(img_dir), 'img_dir not exists'\n",
    "\n",
    "    outfile= os.path.join(img_dir, '{}_{}_{}.{}'.format(idprefix, '_'.join(keyword.split()), len(os.listdir(img_dir)), extension))\n",
    "    print outfile\n",
    "\n",
    "    image_id_url_dict = dict()\n",
    "    for i in range(offset, offset + max_num, 100):\n",
    "        print 'start from', i\n",
    "        url = entryurl_googleimage(initurl, i)\n",
    "        pages =  response_contents(url)\n",
    "        img_id_url_dict = extract_infos_googleimage(pages)\n",
    "\n",
    "        image_id_url_dict.update(img_id_url_dict)\n",
    "\n",
    "    print 'save image_id_url_dict'\n",
    "    save_infos(image_id_url_dict, idprefix, outfile)\n",
    "\n",
    "###############\n",
    "keyword = ''\n",
    "urllist = list()\n",
    "\n",
    "# urllist.append('')\n",
    "# urllist.append('')\n",
    "\n",
    "# urllist.append('')\n",
    "# urllist.append('')\n",
    "# urllist.append('')\n",
    "# urllist.append('')\n",
    "\n",
    "\n",
    "for initurl in urllist:\n",
    "    main(keyword, initurl)\n",
    "    \n",
    "print '########### done ##############'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
